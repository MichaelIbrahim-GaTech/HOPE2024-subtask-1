{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoarJ2NvFuMx",
        "outputId": "8d0f3346-9817-4441-be3d-44cfabf2685f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Sonictherocketman/gzip-classifier\n",
            "  Cloning https://github.com/Sonictherocketman/gzip-classifier to /tmp/pip-req-build-b4kp57gu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Sonictherocketman/gzip-classifier /tmp/pip-req-build-b4kp57gu\n",
            "  Resolved https://github.com/Sonictherocketman/gzip-classifier to commit a5e8579a2f5d3b8c9006ef1cebbe1e07a0907ff1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/Sonictherocketman/gzip-classifier\n",
        "from gzip_classifier import Classifier, ParallelClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQw-h26EM2Xh",
        "outputId": "64beb63d-ddb5-43bd-ba82-b28813cf5f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stop-words in /usr/local/lib/python3.10/dist-packages (2018.7.23)\n"
          ]
        }
      ],
      "source": [
        "!pip install stop-words\n",
        "from stop_words import get_stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGuJCwDlFzq8",
        "outputId": "f0a3b880-374f-4878-8e07-2dd00bd13453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQuBrvDMF2v6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "import gc\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6PEFhjsF5lJ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"drive/MyDrive/HOPE2024/training_t1_sp.csv\")\n",
        "val = pd.read_csv(\"drive/MyDrive/HOPE2024/Task 1 - Validation set .csv\")\n",
        "test = pd.read_csv(\"drive/MyDrive/HOPE2024/Task 1 - Test set No label.csv\")\n",
        "test['category'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgK5jK2DMwyu"
      },
      "outputs": [],
      "source": [
        "sw = get_stop_words('spanish')\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "\n",
        "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs\n",
        "\n",
        "    html=re.compile(r'<.*?>')\n",
        "\n",
        "    text = html.sub(r'',text) #Removing html tags\n",
        "\n",
        "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
        "    for p in punctuations:\n",
        "        text = text.replace(p,'') #Removing punctuations\n",
        "\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "\n",
        "    text = \" \".join(text) #removing stopwords\n",
        "\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCVjl0tnMzUH"
      },
      "outputs": [],
      "source": [
        "#df['text'] = df['text'].apply(lambda x: clean_text(x))\n",
        "#val['text'] = val['text'].apply(lambda x: clean_text(x))\n",
        "#test['text'] = test['text'].apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEk5Otv2GDbK"
      },
      "outputs": [],
      "source": [
        "tweets = np.concatenate([df.text.values,val.text.values])\n",
        "labels = np.concatenate([df.category.values,val.category.values])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_tweets = test.text.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Gf7TzIlGZU-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR4qDpG3Gnv_",
        "outputId": "4fb633b1-85ad-40c2-901b-cf9be4468be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 1072 1600 0.67\n",
            "2 1072 1600 0.67\n",
            "3 1135 1600 0.709375\n",
            "4 1130 1600 0.70625\n",
            "5 1115 1600 0.696875\n",
            "6 1136 1600 0.71\n",
            "7 1138 1600 0.71125\n",
            "8 1143 1600 0.714375\n",
            "9 1136 1600 0.71\n",
            "10 1137 1600 0.710625\n",
            "11 1132 1600 0.7075\n",
            "12 1157 1600 0.723125\n",
            "13 1144 1600 0.715\n",
            "14 1141 1600 0.713125\n",
            "15 1137 1600 0.710625\n",
            "16 1140 1600 0.7125\n",
            "17 1146 1600 0.71625\n",
            "18 1140 1600 0.7125\n",
            "19 1141 1600 0.713125\n",
            "20 1145 1600 0.715625\n",
            "21 1142 1600 0.71375\n",
            "22 1148 1600 0.7175\n",
            "23 1139 1600 0.711875\n",
            "24 1143 1600 0.714375\n",
            "25 1140 1600 0.7125\n",
            "26 1148 1600 0.7175\n",
            "27 1141 1600 0.713125\n",
            "28 1145 1600 0.715625\n",
            "29 1150 1600 0.71875\n"
          ]
        }
      ],
      "source": [
        "for k in range(12,31):\n",
        "\n",
        "  accuracy = 0\n",
        "  total = 0\n",
        "  skf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
        "  for i, (train_index, test_index) in enumerate(skf.split(tweets, labels)):\n",
        "    classifier = Classifier()\n",
        "    classifier.train(tweets[train_index], labels[train_index])\n",
        "    val_tweets = tweets[test_index]\n",
        "    val_labels = labels[test_index]\n",
        "    for i in range(len(val_tweets)):\n",
        "      pred, count, ls = classifier.classify(val_tweets[i],k=k, include_all=True)\n",
        "      if pred == val_labels[i]:\n",
        "        accuracy += 1\n",
        "      total += 1\n",
        "  print(k,accuracy,total,accuracy/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2uOzXXSOOQP"
      },
      "outputs": [],
      "source": [
        "for index, row in test.iterrows():\n",
        "  pred, count, ls = classifier.classify(clean_text(row['text']),k=13, include_all=True)\n",
        "  test.at[index,'category'] = pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSMGf-f-Oipa"
      },
      "outputs": [],
      "source": [
        "test[['id','category']].to_csv('predictions.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}